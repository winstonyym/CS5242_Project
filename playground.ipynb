{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe08266-9789-4736-af56-e390142b977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_pdb_file_20200302 as readpb\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from json import loads, dumps\n",
    "from ast import literal_eval\n",
    "import pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgllife\n",
    "from dgllife.utils import CanonicalAtomFeaturizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Pad\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad12a196-f78d-431c-bc72-88affec645e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_atom2int = {'C':0, 'D':1, 'N':2, 'O':3, 'P':4, 'S':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cb64f1-3ad6-4edc-ba24-a555368ca4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Protein Data Base Files\n",
    "'''\n",
    "Contains atoms and locations that make up the structure of a protein\n",
    "'''\n",
    "proteins_dict = {}\n",
    "for protein in os.listdir(\"./cs5242_project_data/pdbs/\"):\n",
    "    if protein.startswith(\".\"):\n",
    "        pass\n",
    "    else:\n",
    "        x,y,z,group,atom = readpb.read_pdb(os.path.join(\"cs5242_project_data/pdbs/\",protein))\n",
    "        atom = [mapping_atom2int[i] for i in atom]\n",
    "    temp = {}\n",
    "    for i in range(len(x)):\n",
    "        temp[i] = {\"coords\":[x[i],y[i],z[i]], 'group':group[i], \"atom\":atom[i]}\n",
    "        proteins_dict[protein[:4]] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719738f0-0f42-4a74-96bd-c8813deb1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proteins_dict['102D']\n",
    "def gen_amino_list(protein):\n",
    "    \n",
    "    list_of_groups = [i['group'] for i in protein.values()]\n",
    "    # average = np.average(list_of_coords, axis=0)\n",
    "    # print(average)\n",
    "    set_of_groups = set(list_of_groups)\n",
    "    set_of_groups  = dict.fromkeys(list_of_groups, 0)\n",
    "    for k in set_of_groups:\n",
    "        set_of_groups[k] = {'atom':[i['atom'] for i in protein.values() if i['group'] == k], \n",
    "                            'coords':[i['coords'] for i in protein.values() if i['group'] == k]}\n",
    "        \n",
    "        set_of_groups[k]['centroid'] = list(np.average(set_of_groups[k]['coords'],0))\n",
    "    return set_of_groups\n",
    "\n",
    "# set_of_amino = gen_amino_list(proteins_dict['102D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9fa4aa27-12bb-4782-88ae-6d913ecd194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce full list of amino-acid group to embedding map\n",
    "# Code takes a long time to run, instead a json object is saved for loading\n",
    "\n",
    "# full_amino_list = []\n",
    "\n",
    "# for i in proteins_dict:\n",
    "#     amino_group = gen_amino_list(proteins_dict[i])\n",
    "    \n",
    "#     for k in amino_group.values():\n",
    "        \n",
    "#         if k['atom'] not in full_amino_list:\n",
    "#             full_amino_list.append(k['atom'])\n",
    "            \n",
    "# amino_db = {}\n",
    "# for i,item in enumerate(full_amino_list):\n",
    "#     amino_db[tuple(item)] = i\n",
    "    \n",
    "# # save: convert each tuple key to a string before saving as json object\n",
    "# s = dumps({str(k): v for k, v in amino_db.items()})\n",
    "  \n",
    "# # Writing\n",
    "# with open(\"amino_db.json\", \"w\") as outfile:\n",
    "#     outfile.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0493cc-f2ca-486e-8665-206f681c7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) load json object\n",
    "\n",
    "with open('amino_db.json', 'r') as openfile:\n",
    "    json_object = json.load(openfile)\n",
    "\n",
    "# (ii) convert loaded keys from string back to tuple\n",
    "amino_db = {literal_eval(k): v for k, v in json_object.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa4f4f3d-f8e2-4e32-8337-4559c257fd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102D</td>\n",
       "      <td>9.819391</td>\n",
       "      <td>24.178348</td>\n",
       "      <td>71.561739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110M</td>\n",
       "      <td>35.189667</td>\n",
       "      <td>6.802667</td>\n",
       "      <td>12.175667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112M</td>\n",
       "      <td>34.892200</td>\n",
       "      <td>7.174000</td>\n",
       "      <td>12.498400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11BA</td>\n",
       "      <td>-14.688256</td>\n",
       "      <td>14.944487</td>\n",
       "      <td>0.193744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11BG</td>\n",
       "      <td>5.319879</td>\n",
       "      <td>55.114576</td>\n",
       "      <td>66.171818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PID          x          y          z\n",
       "0  102D   9.819391  24.178348  71.561739\n",
       "1  110M  35.189667   6.802667  12.175667\n",
       "2  112M  34.892200   7.174000  12.498400\n",
       "3  11BA -14.688256  14.944487   0.193744\n",
       "4  11BG   5.319879  55.114576  66.171818"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load centroids\n",
    "'''\n",
    "Location of ligand binding site on protein\n",
    "'''\n",
    "centroid_df = pandas.read_csv('./cs5242_project_data/centroids.csv')\n",
    "# null_df = centroid_df.isnull()\n",
    "# row_with_NA = null_df.any(axis=1)\n",
    "# centroid_df[row_with_NA]\n",
    "\n",
    "# Remove NA - PID 1NDE\n",
    "centroid_df = centroid_df.dropna()\n",
    "centroid_df = centroid_df.reset_index(drop=True)\n",
    "centroid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d37e32a-e154-4be8-a1c0-5210381773e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'centroid': [9.819391304, 24.17834783, 71.56173913]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### JOIN PROTEIN AND CENTROID\n",
    "proteins_with_binding = {}\n",
    "for i, protein in enumerate(centroid_df['PID']):\n",
    "    proteins_with_binding[protein] = {'centroid':[centroid_df.loc[i,'x'],centroid_df.loc[i,\"y\"],centroid_df.loc[i,\"z\"]]\n",
    "                                     }\n",
    "proteins_with_binding['102D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25793157-42a3-444b-ad2b-3099ae846d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Protein Embeddings\n",
    "def protein2numeric(protein_id, max_len):    # Get numeric list of amino acids\n",
    "    amino_list = gen_amino_list(proteins_dict[protein_id])\n",
    "    \n",
    "    # sort numeric by distance\n",
    "    neighbors = []\n",
    "    distances = []\n",
    "    centroid = proteins_with_binding[protein_id]['centroid']\n",
    "    for i in amino_list.values():\n",
    "        numeric = amino_db.get(tuple(i['atom']))\n",
    "        dist = np.linalg.norm(np.array(i['centroid'])-np.array(centroid))\n",
    "        distances.append((numeric, dist))\n",
    "    distances.sort(key=lambda tup:tup[1])\n",
    "    \n",
    "    for i in range(len(distances)):\n",
    "        if i < max_len:\n",
    "            neighbors.append(distances[i][0])\n",
    "    if len(neighbors)<max_len:\n",
    "        list = [0] * (max_len-len(neighbors))\n",
    "        neighbors += list\n",
    "        \n",
    "    return torch.Tensor(neighbors)\n",
    "    # return numeric tensor\n",
    "# protein2numeric('102D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701883b7-8dce-46c6-8fb1-a3e68626c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ligand\n",
    "'''\n",
    "Loads ligand ID and SMILES information \n",
    "'''\n",
    "ligand_df = pandas.read_csv('cs5242_project_data/ligand.csv')\n",
    "ligand2class = {}\n",
    "for i,lid in enumerate(ligand_df['LID']):\n",
    "    ligand2class[lid] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3ab2ac6-db9a-4eaf-aa3b-72b4007cb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_SMI_SET = {\"(\": 1, \".\": 2, \"0\": 3, \"2\": 4, \"4\": 5, \"6\": 6, \"8\": 7, \"@\": 8,\n",
    "                \"B\": 9, \"D\": 10, \"F\": 11, \"H\": 12, \"L\": 13, \"N\": 14, \"P\": 15, \"R\": 16,\n",
    "                \"T\": 17, \"V\": 18, \"Z\": 19, \"\\\\\": 20, \"b\": 21, \"d\": 22, \"f\": 23, \"h\": 24,\n",
    "                \"l\": 25, \"n\": 26, \"r\": 27, \"t\": 28, \"#\": 29, \"%\": 30, \")\": 31, \"+\": 32,\n",
    "                \"-\": 33, \"/\": 34, \"1\": 35, \"3\": 36, \"5\": 37, \"7\": 38, \"9\": 39, \"=\": 40,\n",
    "                \"A\": 41, \"C\": 42, \"E\": 43, \"G\": 44, \"I\": 45, \"K\": 46, \"M\": 47, \"O\": 48,\n",
    "                \"S\": 49, \"U\": 50, \"W\": 51, \"Y\": 52, \"[\": 53, \"]\": 54, \"a\": 55, \"c\": 56,\n",
    "                \"e\": 57, \"g\": 58, \"i\": 59, \"m\": 60, \"o\": 61, \"s\": 62, \"u\": 63, \"y\": 64,\n",
    "                \"p\":65, ' ':66}\n",
    "\n",
    "max_len = 50\n",
    "\n",
    "# def ligand2numeric(smiles):\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     atom_featurizer = CanonicalAtomFeaturizer(atom_data_field='feat')\n",
    "#     num = atom_featurizer(mol)['feat']\n",
    "#     # layer_pad = Pad([0,0,0,num.shape[1]-num.shape[0]])\n",
    "#     num = num.view(-1)\n",
    "#     num = F.pad(num, (0, 6734 - len(num)), 'constant', 0)\n",
    "#     return num\n",
    "\n",
    "# list_of_ligands = [ligand2numeric(smiles) for smiles in ligand_df['Smiles']]\n",
    "\n",
    "def ligand2numeric(line, max_len):\n",
    "    X = np.zeros(max_len)\n",
    "    for i, ch in enumerate(line[:max_len]):\n",
    "        X[i] = CHAR_SMI_SET[ch] \n",
    "\n",
    "    return torch.Tensor(X)\n",
    "\n",
    "# ligand2numeric(ligand_df.loc[2,'Smiles'], max_smi_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83d8e954-66fd-46ad-9dad-805e0faa04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pair\n",
    "'''\n",
    "Loads Information of which ligand binds to which protein\n",
    "'''\n",
    "pair_df = pandas.read_csv('cs5242_project_data/pair.csv')\n",
    "pairs_lookup = {}\n",
    "for i in range(len(pair_df)):\n",
    "    pairs_lookup[pair_df.loc[i,'LID']] = pair_df.loc[i,'PID'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20bcd8b7-63d2-4188-8d0d-f17809d0e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Ligand Smiles to PID\n",
    "df = pandas.merge(centroid_df, pair_df, on = 'PID')\n",
    "df = pandas.merge(df, ligand_df, on = 'LID')\n",
    "\n",
    "# labels = np.array(df['LID'])\n",
    "# zeros_matrix = np.zeros((labels.size, labels.max()+1))\n",
    "# zeros_matrix[np.arange(labels.size),labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f093ff5c-41b1-4caf-b8fb-a6fbb3a82596",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "range_index = range(len(df))\n",
    "random_index = np.random.permutation(range_index)\n",
    "training_idx, valid_idx, test_idx = random_index[0:int(0.7*len(df))], random_index[int(0.7*len(df)):int(0.85*len(df))], random_index[int(0.85*len(df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e1b24ed7-7fd5-449a-8e33-42d5094bae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate list of ligand embeddings\n",
    "# ligand_embeddings = [ligand2numeric(ligand_df.loc[k,'Smiles'], max_len) for k in range(len(ligand_df))]\n",
    "\n",
    "# # Generate list of protein embeddings\n",
    "# protein_embeddings = [protein2numeric(k, max_len) for k in proteins_with_binding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "886f6be7-5934-43ef-9dc3-c9558c8fd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a function to generate negative samples \n",
    "def random_sample(no_of_samples=no_of_samples):\n",
    "    random_ligands = np.random.randint(0, len(ligand_df), no_of_samples)\n",
    "    random_proteins = random.sample(list(proteins_with_binding), no_of_samples)\n",
    "    wrong_tensor = torch.zeros(size=(no_of_samples,max_len*2))\n",
    "    for i,item in enumerate(zip(random_ligands,random_proteins)):\n",
    "        wrong_tensor[i,:] = torch.cat((ligand2numeric(ligand_df.loc[item[0],'Smiles'], max_len), protein2numeric(item[1], max_len)))\n",
    "        \n",
    "    label = torch.zeros(size=(no_of_samples,))\n",
    "    for i,item in enumerate(zip(random_ligands,random_proteins)):\n",
    "        if item[0] in pairs_lookup:\n",
    "            if pairs_lookup[item[0]] == item[1]:\n",
    "                label[i] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return wrong_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c234789-7a2f-42dc-bdb2-cba7f48caadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1OF1', '1UUM', '1PKE', ..., '2XFH', '2I0Y', '2VVT'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = df.loc[training_idx,:]\n",
    "np.array(traindf['PID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b8e5f9b9-8758-4fcf-8333-75043daeaae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sample(df, idx):\n",
    "    traindf = df.loc[training_idx,:]\n",
    "    correct_ligands = np.array(traindf['Smiles'])\n",
    "    correct_proteins = np.array(traindf['PID'])\n",
    "    correct_tensor = torch.zeros(size=(len(traindf),max_len*2))\n",
    "    for i,item in enumerate(zip(correct_ligands,correct_proteins)):\n",
    "        correct_tensor[i,:] = torch.cat((ligand2numeric(item[0], max_len), protein2numeric(item[1], max_len)))\n",
    "        \n",
    "    label = torch.ones(size=(len(traindf),))\n",
    "\n",
    "    return correct_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "11730255-2744-4ed7-9530-0f0812173519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL PARAMETERS\n",
    "no_of_samples = 1000\n",
    "max_len = 50\n",
    "num_epochs = 10\n",
    "num_classes = 3424\n",
    "batch_size = 8\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "daa00a92-0721-4012-a81b-c180ed691166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE DATASET AND DATALOADERS\n",
    "\n",
    "class PLI_Dataset(Dataset):\n",
    "    \"\"\"Returns protein, ligand, and output sequence.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, split):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe - df file\n",
    "            split - train, valid, or test\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "        if split == 'train':\n",
    "            correct_tensor, label = correct_sample(self.dataframe, training_idx)\n",
    "            wrong_tensor, wlabel = random_sample(no_of_samples=no_of_samples)\n",
    "            self.split = torch.cat((correct_tensor,wrong_tensor))\n",
    "            self.label = torch.cat((label,wlabel))\n",
    "            \n",
    "        elif split == 'valid':\n",
    "            correct_tensor, label = correct_sample(self.dataframe, valid_idx)\n",
    "            wrong_tensor, wlabel = random_sample(no_of_samples=no_of_samples)\n",
    "            self.split = torch.cat((correct_tensor,wrong_tensor))\n",
    "            self.label = torch.cat((label,wlabel))\n",
    "            \n",
    "        elif split == 'test': \n",
    "            correct_tensor, label = correct_sample(self.dataframe, test_idx)\n",
    "            wrong_tensor, wlabel = random_sample(no_of_samples=no_of_samples)\n",
    "            self.split = torch.cat((correct_tensor,wrong_tensor))\n",
    "            self.label = torch.cat((label,wlabel))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.split)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        embedding = self.split[idx]\n",
    "        output = self.label[idx]\n",
    "\n",
    "        return embedding, output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "238022ba-fc64-42ff-b6c5-400a08f690d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-519e4d98fda9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m datasets = {\"train_set\" : PLI_Dataset(dataframe = df, split = 'train'), \n\u001b[1;32m      2\u001b[0m             \u001b[0;34m\"val_set\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mPLI_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m             \u001b[0;34m\"test_set\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mPLI_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m            }\n\u001b[1;32m      5\u001b[0m dataloaders = {\"train_loader\": torch.utils.data.DataLoader(dataset=datasets[\"train_set\"], batch_size=8,shuffle=True,drop_last=True),\n",
      "\u001b[0;32m<ipython-input-128-834d7e2b2391>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, split)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcorrect_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mwrong_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_of_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_of_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrong_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-dcfcf168478d>\u001b[0m in \u001b[0;36mcorrect_sample\u001b[0;34m(df, idx)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcorrect_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_ligands\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorrect_proteins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcorrect_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mligand2numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein2numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-b03b300f0a79>\u001b[0m in \u001b[0;36mprotein2numeric\u001b[0;34m(protein_id, max_len)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate Protein Embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprotein2numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# Get numeric list of amino acids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mamino_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_amino_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproteins_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprotein_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# sort numeric by distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2b9c926c24e2>\u001b[0m in \u001b[0;36mgen_amino_list\u001b[0;34m(protein)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset_of_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         set_of_groups[k] = {'atom':[i['atom'] for i in protein.values() if i['group'] == k], \n\u001b[0;32m---> 11\u001b[0;31m                             'coords':[i['coords'] for i in protein.values() if i['group'] == k]}\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mset_of_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'centroid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_of_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2b9c926c24e2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset_of_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         set_of_groups[k] = {'atom':[i['atom'] for i in protein.values() if i['group'] == k], \n\u001b[0;32m---> 11\u001b[0;31m                             'coords':[i['coords'] for i in protein.values() if i['group'] == k]}\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mset_of_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'centroid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_of_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets = {\"train_set\" : PLI_Dataset(dataframe = df, split = 'train'), \n",
    "            \"val_set\" : PLI_Dataset(dataframe = df, split = 'valid'),\n",
    "            \"test_set\" : PLI_Dataset(dataframe = df, split = 'train')\n",
    "           }\n",
    "dataloaders = {\"train_loader\": torch.utils.data.DataLoader(dataset=datasets[\"train_set\"], batch_size=8,shuffle=True,drop_last=True),\n",
    "               \"val_loader\": torch.utils.data.DataLoader(dataset=datasets[\"val_set\"], batch_size=8,shuffle=True,drop_last=True),\n",
    "               \"test_loader\": torch.utils.data.DataLoader(dataset=datasets[\"test_set\"], batch_size=8,shuffle=True,drop_last=True)\n",
    "              }\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a320a-f9a3-4729-88b8-3ab98f39a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, output = next(iter(dataloaders['train_loader']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0bf38ca-5754-4cc6-b798-ad46834cb7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 21, 100])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9075c212-b759-4796-ba1c-7faa973bdab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 21])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28317694-855e-4237-9962-11a941e3b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, num_classes=num_classes, device='cpu'):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # DEFINE NN MODULES\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1_1 = nn.Linear(in_features=100, out_features=32)\n",
    "        self.fc2_1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.classifier = nn.Linear(in_features=32, out_features=2)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "    # DEFINE FORWARD FUNCTIONS\n",
    "    \n",
    "        x_out = self.batchnorm1(self.fc1_1(x))\n",
    "        x_out = self.relu(x_out)\n",
    "        x_out = self.batchnorm2(self.fc2_1(x_out))\n",
    "        x_out = self.relu(x_out)\n",
    "        out = self.classifier(x_out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def inference(self, PID, PDBS_DIR, centroid, ligands):\n",
    "\n",
    "        p = self.process_PDB(PID, PDBS_DIR).to(self.device)\n",
    "        c = self.process_coord(centroid).to(self.device)\n",
    "        l = self.batch_process_SMILE(ligands).to(self.device)\n",
    "        return self.forward(p, c, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff74d226-2078-4ac6-be2d-7f4092d2757b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([168])) must be the same as input size (torch.Size([168, 2]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-67fcaf0320d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cs5242/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cs5242/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cs5242/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([168])) must be the same as input size (torch.Size([168, 2]))"
     ]
    }
   ],
   "source": [
    "model = MLPNet().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(dataloaders['train_loader'])\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (embedding, target) in enumerate(dataloaders['train_loader']):\n",
    "        embedding = embedding.reshape((8*21,100))\n",
    "        target = target.reshape(-1)\n",
    "        \n",
    "        embedding = embedding.to(device)\n",
    "        target = target.to(device)\n",
    "        # Forward pass\n",
    "        output = model(embedding)\n",
    "        loss = criterion(output, target)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    # model.eval()  \n",
    "    # with torch.no_grad():\n",
    "    #     correct = 0\n",
    "    #     total = 0\n",
    "    #     for i, (protein, ligand, target) in enumerate(dataloaders['val_loader']):\n",
    "    #         ligand = ligand.to(device)\n",
    "    #         protein = protein.to(device)\n",
    "    #         target = target.to(device)\n",
    "    #         output = model(protein, ligand)\n",
    "    #         _, predicted = torch.topk(output.data, 10, 1)\n",
    "    #         total += target.size(0)\n",
    "    #         for i in range(target.size(0)):\n",
    "    #             if target[i] in predicted[i]:\n",
    "    #                 correct += 1\n",
    "    #             else:\n",
    "    #                 pass\n",
    "    #     print('Val accuracy on validation set: {} %'.format(100 * correct / total))\n",
    "        \n",
    "# # Save the model checkpoint\n",
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb006603-bb60-460a-9ac8-b285d5a6bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()  \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (protein, ligand, target) in enumerate(dataloaders['val_loader']):\n",
    "        ligand = ligand.to(device)\n",
    "        protein = protein.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(protein, ligand)\n",
    "        _, predicted = torch.topk(output.data, 10, 1)\n",
    "        total += target.size(0)\n",
    "        for i in range(target.size(0)):\n",
    "            if target[i] in predicted[i]:\n",
    "                correct += 1\n",
    "            else:\n",
    "                pass\n",
    "    print(total)\n",
    "    print('Val accuracy on validation set: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a24ec-d54d-403c-aa5f-a7065eb2c54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5242",
   "language": "python",
   "name": "cs5242"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
